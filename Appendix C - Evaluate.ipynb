{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.models import load_model\n",
    "import opticspy\n",
    "import random\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = ''\n",
    "# for using on local windows machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple scaling normalization\n",
    "def zernike_gen(batch_size=16,sqr_grid_width=50):\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        train_coeff = np.transpose([[random.uniform(-2.,3.) for Z1 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z2 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z3 in range(batch_size)],\n",
    "                                    [random.uniform(-9.,5.) for Z4 in range(batch_size)],\n",
    "                                    [random.uniform(-4.,2.) for Z5 in range(batch_size)],\n",
    "                                    [random.uniform(-3.,3.2) for Z6 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.4) for Z7 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z8 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z9 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z10 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z11 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z12 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z13 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z14 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z15 in range(batch_size)]])\n",
    "        \n",
    "#         Divide x and y by 49 to normalize between 0 and 1\n",
    "        x = np.array([np.array([[i for i in range(sqr_grid_width)] for x in range(sqr_grid_width)]).flatten()\n",
    "                           for z in range(batch_size)])/float(sqr_grid_width)\n",
    "        y = np.array([np.array([[y for i in range(sqr_grid_width)] for y in range(sqr_grid_width)]).flatten()\n",
    "                           for z in range(batch_size)])/float(sqr_grid_width)\n",
    "\n",
    "\n",
    "        # z_grid to be used to create training data for dx and dy to create the gradient data\n",
    "        z_grid_train = np.array([np.array(opticspy.zernike.Coefficient(Z1=train_coeff[z][0],\n",
    "                            Z2=train_coeff[z][1], Z3=train_coeff[z][2], Z4=train_coeff[z][3], Z5=train_coeff[z][4],\n",
    "                            Z6=train_coeff[z][5], Z7=train_coeff[z][6], Z8=train_coeff[z][7], Z9=train_coeff[z][8],\n",
    "                            Z10=train_coeff[z][9], Z11=train_coeff[z][10], Z12=train_coeff[z][11], Z13=train_coeff[z][12],\n",
    "                            Z14=train_coeff[z][13], Z15=train_coeff[z][14]).zernikematrix(l=sqr_grid_width))\n",
    "                            for z in range(batch_size)])\n",
    "\n",
    "\n",
    "        gradient_train = [np.gradient(z_grid_train[i]) for i in range(batch_size)]\n",
    "        \n",
    "#         Divide by 10 to keep numbers near the -1 to 1 range\n",
    "        dx_train = np.array([np.array([x for x in gradient_train[i][0]]).flatten() for i in range(batch_size)])\n",
    "        dy_train = np.array([np.array([y for y in gradient_train[i][1]]).flatten() for i in range(batch_size)])\n",
    "\n",
    "        train_input = np.array([np.transpose([x[i], y[i], dx_train[i], dy_train[i]])\n",
    "                      for i in range(batch_size)])\n",
    "\n",
    "        yield train_input,train_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zernike_gen_ones(batch_size=16,sqr_grid_width=50):\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        train_coeff = np.transpose([[random.uniform(-1.,1.) for Z1 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z2 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z3 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z4 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z5 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z6 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z7 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z8 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z9 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z10 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z11 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z12 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z13 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z14 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z15 in range(batch_size)]])\n",
    "        \n",
    "#         Divide x and y by 49 to normalize between 0 and 1\n",
    "        x = np.array([np.array([[i for i in range(sqr_grid_width)] for x in range(sqr_grid_width)]).flatten()\n",
    "                           for z in range(batch_size)])/float(sqr_grid_width)\n",
    "        y = np.array([np.array([[y for i in range(sqr_grid_width)] for y in range(sqr_grid_width)]).flatten()\n",
    "                           for z in range(batch_size)])/float(sqr_grid_width)\n",
    "\n",
    "\n",
    "        # z_grid to be used to create training data for dx and dy to create the gradient data\n",
    "        z_grid_train = np.array([np.array(opticspy.zernike.Coefficient(Z1=train_coeff[z][0],\n",
    "                            Z2=train_coeff[z][1], Z3=train_coeff[z][2], Z4=train_coeff[z][3], Z5=train_coeff[z][4],\n",
    "                            Z6=train_coeff[z][5], Z7=train_coeff[z][6], Z8=train_coeff[z][7], Z9=train_coeff[z][8],\n",
    "                            Z10=train_coeff[z][9], Z11=train_coeff[z][10], Z12=train_coeff[z][11], Z13=train_coeff[z][12],\n",
    "                            Z14=train_coeff[z][13], Z15=train_coeff[z][14]).zernikematrix(l=sqr_grid_width))\n",
    "                            for z in range(batch_size)])\n",
    "\n",
    "\n",
    "        gradient_train = [np.gradient(z_grid_train[i]) for i in range(batch_size)]\n",
    "        \n",
    "        dx_train = np.array([np.array([x for x in gradient_train[i][0]]).flatten() for i in range(batch_size)])\n",
    "        dy_train = np.array([np.array([y for y in gradient_train[i][1]]).flatten() for i in range(batch_size)])\n",
    "\n",
    "        train_input = np.array([np.transpose([x[i], y[i], dx_train[i], dy_train[i]])\n",
    "                      for i in range(batch_size)])\n",
    "\n",
    "        yield train_input,train_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "va9qaeZv-9L_"
   },
   "outputs": [],
   "source": [
    "def block_gen(min_blk=2,max_blk=10,sqr_grid_width=50):\n",
    "    x_block_size = randrange(min_blk,max_blk+1) \n",
    "    x_block_start = randrange(sqr_grid_width-1-x_block_size) \n",
    "    x_block = np.array(range(x_block_start,x_block_start+x_block_size))/float(sqr_grid_width)\n",
    "\n",
    "    y_block_size = randrange(min_blk,max_blk+1) \n",
    "    y_block_start = randrange(sqr_grid_width-1-y_block_size) \n",
    "    y_block = np.array(range(y_block_start,y_block_start+y_block_size))/float(sqr_grid_width)\n",
    "    \n",
    "    return x_block,y_block\n",
    "\n",
    "y_mask = lambda y,batch,block: np.isin(y[batch][:,1],block)\n",
    "\n",
    "x_mask = lambda x,batch,block: np.isin(x[batch][:,0],block)\n",
    "\n",
    "def zernike_gen_block(batch_size=16,sqr_grid_width=50):\n",
    "   \n",
    "    while True:\n",
    "        \n",
    "        train_coeff = np.transpose([[random.uniform(-2.,3.) for Z1 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z2 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z3 in range(batch_size)],\n",
    "                                    [random.uniform(-9.,5.) for Z4 in range(batch_size)],\n",
    "                                    [random.uniform(-4.,2.) for Z5 in range(batch_size)],\n",
    "                                    [random.uniform(-3.,3.2) for Z6 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.4) for Z7 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z8 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z9 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z10 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z11 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z12 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z13 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z14 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z15 in range(batch_size)]])\n",
    "\n",
    "\n",
    "        x = np.array([np.array([[i for i in range(sqr_grid_width)] for x in range(sqr_grid_width)]).flatten()\n",
    "                           for z in range(batch_size)])/float(sqr_grid_width)\n",
    "\n",
    "        y = np.array([np.array([[y for i in range(sqr_grid_width)] for y in range(sqr_grid_width)]).flatten()\n",
    "                           for z in range(batch_size)])/float(sqr_grid_width)\n",
    "\n",
    "\n",
    "        # z_grid to be used to create training data for dx and dy to create the gradient data\n",
    "        z_grid_train = np.array([np.array(opticspy.zernike.Coefficient(Z1=train_coeff[z][0],\n",
    "                            Z2=train_coeff[z][1], Z3=train_coeff[z][2], Z4=train_coeff[z][3], Z5=train_coeff[z][4],\n",
    "                            Z6=train_coeff[z][5], Z7=train_coeff[z][6], Z8=train_coeff[z][7], Z9=train_coeff[z][8],\n",
    "                            Z10=train_coeff[z][9], Z11=train_coeff[z][10], Z12=train_coeff[z][11], Z13=train_coeff[z][12],\n",
    "                            Z14=train_coeff[z][13], Z15=train_coeff[z][14]).zernikematrix(l=sqr_grid_width))\n",
    "                            for z in range(batch_size)])\n",
    "\n",
    "\n",
    "        gradient_train = [np.gradient(z_grid_train[i]) for i in range(batch_size)]\n",
    "\n",
    "        dx_train = np.array([np.array([x for x in gradient_train[i][0]]).flatten() for i in range(batch_size)])\n",
    "        dy_train = np.array([np.array([y for y in gradient_train[i][1]]).flatten() for i in range(batch_size)])\n",
    "\n",
    "        train_input = np.array([np.transpose([x[i], y[i], dx_train[i], dy_train[i]])\n",
    "                            for i in range(batch_size)])\n",
    "\n",
    "    #     NOTE: every sample in batch has the same block removed with this set up?\n",
    "    #     Generate random block\n",
    "        x_block,y_block = block_gen(min_blk=2,max_blk=10,sqr_grid_width=sqr_grid_width)\n",
    "\n",
    "    #     Remove random block\n",
    "        for i in range(batch_size):\n",
    "            train_input[i][(y_mask(train_input,i,y_block)) & (x_mask(train_input,i,x_block))] = 0\n",
    "\n",
    "\n",
    "        yield train_input,train_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BHee32fS-9MB"
   },
   "outputs": [],
   "source": [
    "# Create random matrix to add to dx and dy\n",
    "def add_noise(original,batch_size=1,mu=0,sigma=.01):\n",
    "    noise = [[random.gauss(mu, sigma) for x in range(len(original[0]))] for i in range(batch_size)]\n",
    "    mod_data = original + noise\n",
    "    return np.array(mod_data)\n",
    "\n",
    "def zernike_gen_noise(batch_size=16,sqr_grid_width=50):\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        train_coeff = np.transpose([[random.uniform(-2.,3.) for Z1 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z2 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z3 in range(batch_size)],\n",
    "                                    [random.uniform(-9.,5.) for Z4 in range(batch_size)],\n",
    "                                    [random.uniform(-4.,2.) for Z5 in range(batch_size)],\n",
    "                                    [random.uniform(-3.,3.2) for Z6 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.4) for Z7 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z8 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z9 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z10 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z11 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z12 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z13 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z14 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z15 in range(batch_size)]])\n",
    "\n",
    "        x = np.array([np.array([[i for i in range(sqr_grid_width)] for x in range(sqr_grid_width)]).flatten()\n",
    "                           for z in range(batch_size)])/float(sqr_grid_width)\n",
    "        y = np.array([np.array([[y for i in range(sqr_grid_width)] for y in range(sqr_grid_width)]).flatten()\n",
    "                           for z in range(batch_size)])/float(sqr_grid_width)\n",
    "\n",
    "\n",
    "        # z_grid to be used to create training data for dx and dy to create the gradient data\n",
    "        z_grid_train = np.array([np.array(opticspy.zernike.Coefficient(Z1=train_coeff[z][0],\n",
    "                            Z2=train_coeff[z][1], Z3=train_coeff[z][2], Z4=train_coeff[z][3], Z5=train_coeff[z][4],\n",
    "                            Z6=train_coeff[z][5], Z7=train_coeff[z][6], Z8=train_coeff[z][7], Z9=train_coeff[z][8],\n",
    "                            Z10=train_coeff[z][9], Z11=train_coeff[z][10], Z12=train_coeff[z][11], Z13=train_coeff[z][12],\n",
    "                            Z14=train_coeff[z][13], Z15=train_coeff[z][14]).zernikematrix(l=sqr_grid_width))\n",
    "                            for z in range(batch_size)])\n",
    "\n",
    "\n",
    "        gradient_train = [np.gradient(z_grid_train[i]) for i in range(batch_size)]\n",
    "\n",
    "        dx_train = np.array([np.array([x for x in gradient_train[i][0]]).flatten() for i in range(batch_size)])\n",
    "        dx_noise = add_noise(dx_train,batch_size=batch_size)\n",
    "\n",
    "        dy_train = np.array([np.array([y for y in gradient_train[i][1]]).flatten() for i in range(batch_size)])\n",
    "        dy_noise = add_noise(dy_train,batch_size=batch_size)\n",
    "\n",
    "        train_input = np.array([np.transpose([x[i], y[i], dx_noise[i], dy_noise[i]])\n",
    "                      for i in range(batch_size)])\n",
    "\n",
    "        yield train_input,train_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BHee32fS-9MB"
   },
   "outputs": [],
   "source": [
    "# Create random matrix to add to dx and dy and block region\n",
    "def zernike_gen_blocknoise(batch_size=16,sqr_grid_width=50):\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        train_coeff = np.transpose([[random.uniform(-2.,3.) for Z1 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z2 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z3 in range(batch_size)],\n",
    "                                    [random.uniform(-9.,5.) for Z4 in range(batch_size)],\n",
    "                                    [random.uniform(-4.,2.) for Z5 in range(batch_size)],\n",
    "                                    [random.uniform(-3.,3.2) for Z6 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.4) for Z7 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z8 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z9 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z10 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z11 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z12 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z13 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z14 in range(batch_size)],\n",
    "                                    [random.uniform(-1.,1.) for Z15 in range(batch_size)]])\n",
    "\n",
    "        x = np.array([np.array([[i for i in range(sqr_grid_width)] for x in range(sqr_grid_width)]).flatten()\n",
    "                           for z in range(batch_size)])/float(sqr_grid_width)\n",
    "        y = np.array([np.array([[y for i in range(sqr_grid_width)] for y in range(sqr_grid_width)]).flatten()\n",
    "                           for z in range(batch_size)])/float(sqr_grid_width)\n",
    "\n",
    "\n",
    "        # z_grid to be used to create training data for dx and dy to create the gradient data\n",
    "        z_grid_train = np.array([np.array(opticspy.zernike.Coefficient(Z1=train_coeff[z][0],\n",
    "                            Z2=train_coeff[z][1], Z3=train_coeff[z][2], Z4=train_coeff[z][3], Z5=train_coeff[z][4],\n",
    "                            Z6=train_coeff[z][5], Z7=train_coeff[z][6], Z8=train_coeff[z][7], Z9=train_coeff[z][8],\n",
    "                            Z10=train_coeff[z][9], Z11=train_coeff[z][10], Z12=train_coeff[z][11], Z13=train_coeff[z][12],\n",
    "                            Z14=train_coeff[z][13], Z15=train_coeff[z][14]).zernikematrix(l=sqr_grid_width))\n",
    "                            for z in range(batch_size)])\n",
    "\n",
    "\n",
    "        gradient_train = [np.gradient(z_grid_train[i]) for i in range(batch_size)]\n",
    "\n",
    "        dx_train = np.array([np.array([x for x in gradient_train[i][0]]).flatten() for i in range(batch_size)])\n",
    "        dx_noise = add_noise(dx_train,batch_size=batch_size)\n",
    "\n",
    "        dy_train = np.array([np.array([y for y in gradient_train[i][1]]).flatten() for i in range(batch_size)])\n",
    "        dy_noise = add_noise(dy_train,batch_size=batch_size)\n",
    "\n",
    "        train_input = np.array([np.transpose([x[i], y[i], dx_noise[i], dy_noise[i]])\n",
    "                      for i in range(batch_size)])\n",
    "        \n",
    "#     NOTE: every sample in batch has the same block removed with this set up?\n",
    "#     Generate random block\n",
    "        x_block,y_block = block_gen(min_blk=2,max_blk=10,sqr_grid_width=sqr_grid_width)\n",
    "\n",
    "#     Remove random block\n",
    "        for i in range(batch_size):\n",
    "            train_input[i][(y_mask(train_input,i,y_block)) & (x_mask(train_input,i,x_block))] = 0\n",
    "\n",
    "        yield train_input,train_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_prefab(test_num,parent_dir,x,y):\n",
    "    os.chdir(parent_dir + '.\\\\Test_{}'.format(test_num))\n",
    "    test_model = load_model('model_test_{}.h5'.format(test_num))\n",
    "#     test_model = load_model('epoch.20.hdf5')\n",
    "    return test_model.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_gen(test_num,parent_dir,gen,steps=1000,verbose=0,name_append=''):\n",
    "    os.chdir(parent_dir + '.\\\\Test_{}{}'.format(test_num,name_append))\n",
    "    test_model = load_model('model_test_{}.h5'.format(test_num))\n",
    "    return test_model,test_model.evaluate_generator(gen,steps=steps,verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASELINE MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Perfect Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_gen = zernike_gen(batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 38s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "test_model,score = eval_model_gen(6,parent_dir,z_gen,verbose=1,name_append='_Perfect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'mean_absolute_error'] \n",
      " [0.14063341136835517, 0.09204327921569347]\n"
     ]
    }
   ],
   "source": [
    "print(test_model.metrics_names,'\\n',score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Blocked Region Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_gen_block = zernike_gen_block(batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 33s 33ms/step\n"
     ]
    }
   ],
   "source": [
    "test_model_block,score_block = eval_model_gen(6,parent_dir,z_gen_block,verbose=1,name_append='_Perfect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'mean_absolute_error'] \n",
      " [0.14378102636523546, 0.12326099549606442]\n"
     ]
    }
   ],
   "source": [
    "print(test_model_block.metrics_names,'\\n',score_block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Noisy Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_gen_noise = zernike_gen_noise(batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 59s 59ms/step\n"
     ]
    }
   ],
   "source": [
    "test_model_noise,score_noise = eval_model_gen(6,parent_dir,z_gen_noise,verbose=1,name_append='_Perfect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'mean_absolute_error'] \n",
      " [0.1390327976681292, 0.09443452239781618]\n"
     ]
    }
   ],
   "source": [
    "print(test_model_noise.metrics_names,'\\n',score_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Noisy Blocked Region Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_gen_blocknoise = zernike_gen_blocknoise(batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 54s 54ms/step\n"
     ]
    }
   ],
   "source": [
    "test_model_blocknoise,score_blocknoise = eval_model_gen(6,parent_dir,z_gen_blocknoise,verbose=1,name_append='_Perfect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'mean_absolute_error'] \n",
      " [0.14284816898033023, 0.12319548914581538]\n"
     ]
    }
   ],
   "source": [
    "print(test_model_blocknoise.metrics_names,'\\n',score_blocknoise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLOCKED AND NOISY MODEL EVALUATION (Continued Training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Perfect Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 38s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "test_model2,score2 = eval_model_gen(6,parent_dir,z_gen,verbose=1,name_append='_BlockNoise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'mean_absolute_error'] \n",
      " [0.1422210692409426, 0.1083152702189982]\n"
     ]
    }
   ],
   "source": [
    "print(test_model2.metrics_names,'\\n',score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Blocked Region Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 34s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "test_model_block2,score_block2 = eval_model_gen(6,parent_dir,z_gen_block,verbose=1,name_append='_BlockNoise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'mean_absolute_error'] \n",
      " [0.14414166660420596, 0.12189801286533475]\n"
     ]
    }
   ],
   "source": [
    "print(test_model_block2.metrics_names,'\\n',score_block2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Noisy Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 57s 57ms/step\n"
     ]
    }
   ],
   "source": [
    "test_model_noise2,score_noise2 = eval_model_gen(6,parent_dir,z_gen_noise,verbose=1,name_append='_BlockNoise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'mean_absolute_error'] \n",
      " [0.13888896559737623, 0.10882283739000559]\n"
     ]
    }
   ],
   "source": [
    "print(test_model_noise2.metrics_names,'\\n',score_noise2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Noisy Blocked Region Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 52s 52ms/step\n"
     ]
    }
   ],
   "source": [
    "test_model_blocknoise2,score_blocknoise2 = eval_model_gen(6,parent_dir,z_gen_blocknoise,verbose=1,name_append='_BlockNoise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'mean_absolute_error'] \n",
      " [0.1424532379861921, 0.121871656909585]\n"
     ]
    }
   ],
   "source": [
    "print(test_model_blocknoise2.metrics_names,'\\n',score_blocknoise2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLOCKED AND NOISY MODEL EVALUATION (Trained With Random Weight Initialization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Perfect Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 35s 35ms/step\n"
     ]
    }
   ],
   "source": [
    "test_model3,score3 = eval_model_gen(6,parent_dir,z_gen,verbose=1,name_append='_scratch_blocknoise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'mean_absolute_error'] \n",
      " [0.13947648993507028, 0.10576432262361049]\n"
     ]
    }
   ],
   "source": [
    "print(test_model3.metrics_names,'\\n',score3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Blocked Region Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 36s 36ms/step\n"
     ]
    }
   ],
   "source": [
    "test_model_block3,score_block3 = eval_model_gen(6,parent_dir,z_gen_block,verbose=1,name_append='_scratch_blocknoise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'mean_absolute_error'] \n",
      " [0.14239149259962142, 0.11346308523416519]\n"
     ]
    }
   ],
   "source": [
    "print(test_model_block3.metrics_names,'\\n',score_block3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Noisy Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 55s 55ms/step\n"
     ]
    }
   ],
   "source": [
    "test_model_noise3,score_noise3 = eval_model_gen(6,parent_dir,z_gen_noise,verbose=1,name_append='_scratch_blocknoise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'mean_absolute_error'] \n",
      " [0.1429164920654148, 0.10787252231687307]\n"
     ]
    }
   ],
   "source": [
    "print(test_model_noise3.metrics_names,'\\n',score_noise3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Noisy Blocked Region Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 54s 54ms/step\n"
     ]
    }
   ],
   "source": [
    "test_model_blocknoise3,score_blocknoise3 = eval_model_gen(6,parent_dir,z_gen_blocknoise,verbose=1,\n",
    "                                                          name_append='_scratch_blocknoise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'mean_absolute_error'] \n",
      " [0.14215625939145685, 0.11339534016698599]\n"
     ]
    }
   ],
   "source": [
    "print(test_model_blocknoise3.metrics_names,'\\n',score_blocknoise3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
